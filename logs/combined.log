2025-08-22 14:54:38 [INFO]: POST / 200 - 3471ms
2025-08-22 14:55:37 [INFO]: POST /api 404 - 2ms
2025-08-22 15:15:10 [INFO]: Environment variables loaded
2025-08-22 15:15:10 [INFO]: Swagger configuration loaded
2025-08-22 15:15:10 [INFO]: Server is running on port 3000
2025-08-22 15:18:09 [INFO]: Environment variables loaded
2025-08-22 15:18:09 [INFO]: Swagger configuration loaded
2025-08-22 15:18:09 [INFO]: Server is running on port 3000
2025-08-22 15:18:19 [INFO]: POST /api 404 - 55ms
2025-08-22 15:18:25 [INFO]: Received chat request
2025-08-22 15:18:25 [INFO]: Calling Ollama service
2025-08-22 15:18:28 [INFO]: Ollama service response received
2025-08-22 15:18:28 [INFO]: Sending chat response
2025-08-22 15:18:28 [INFO]: POST / 200 - 2575ms
2025-08-22 15:19:08 [INFO]: POST /api 404 - 4ms
2025-08-22 15:19:30 [INFO]: POST /api 404 - 2ms
2025-08-22 15:19:33 [INFO]: Received chat request
2025-08-22 15:19:33 [INFO]: Calling Ollama service
2025-08-22 15:19:33 [ERROR]: Application error
TypeError: fetch failed
    at node:internal/deps/undici/undici:13510:13
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async post (file:///home/d3xb0t/Dev/Node/ChatBot/backend/node_modules/ollama/dist/browser.mjs:131:20)
    at async Ollama.processStreamableRequest (file:///home/d3xb0t/Dev/Node/ChatBot/backend/node_modules/ollama/dist/browser.mjs:277:22)
    at async chatOllama (file:///home/d3xb0t/Dev/Node/ChatBot/backend/src/service/ollama.service.js:14:17)
    at async file:///home/d3xb0t/Dev/Node/ChatBot/backend/src/controller/ollama.controller.js:48:22
2025-08-22 15:19:33 [INFO]: POST / 503 - 11ms
